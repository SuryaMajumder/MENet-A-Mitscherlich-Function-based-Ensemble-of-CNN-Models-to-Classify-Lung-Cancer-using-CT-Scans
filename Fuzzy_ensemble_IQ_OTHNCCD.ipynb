{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KffHnnQycKEt"
      },
      "source": [
        "# **Operations to be done with google drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSJFL0V0aMok",
        "outputId": "6846d3b9-7d33-4a65-83ac-522c8d87ad87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Linking with Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXKsyAjnY7sK"
      },
      "source": [
        "# **Data Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iGUKu6hx10-O"
      },
      "outputs": [],
      "source": [
        "#@title Requirements\n",
        "\n",
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choosing Resources\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "   tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IbihwctvY6lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Cleansing\n",
        "\n",
        "import cv2\n",
        "import imghdr\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "data_dir = ['/content/drive/My Drive/Colab Notebooks/data']\n",
        "\n",
        "image_exts = ['jpg', 'jpeg', 'png', 'bmp']\n",
        "\n",
        "for i in data_dir:\n",
        "    for image_class in os.listdir(i):\n",
        "        for image in os.listdir(os.path.join(i, image_class)):\n",
        "            image_path = os.path.join(i, image_class, image)\n",
        "            try:\n",
        "                img = cv2.imread(image_path)\n",
        "                tip = imghdr.what(image_path)\n",
        "                if tip not in image_exts:\n",
        "                    print('Image not in ext list {}'.format(image_path))\n",
        "                    os.remove(image_path)\n",
        "            except Exception as e:\n",
        "                print('Issue with image {}'.format(image_path))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "I6YHjYVQZBSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "huZqVE0-T3h5"
      },
      "outputs": [],
      "source": [
        "#@title Creating Data Pipeline\n",
        "import numpy as np\n",
        "\n",
        "data = tf.keras.utils.image_dataset_from_directory('/content/drive/My Drive/Colab Notebooks/data', shuffle=True)\n",
        "\n",
        "data_iterator = data.as_numpy_iterator()\n",
        "batch = data_iterator.next()\n",
        "print(\"Batch classes: \", batch[1])\n",
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for idx, img in enumerate(batch[0][:4]):\n",
        "    ax[idx].imshow(img.astype(int))\n",
        "    ax[idx].title.set_text(batch[1][idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MT0LWAfOT5qa"
      },
      "outputs": [],
      "source": [
        "#@title Preprocessing Data\n",
        "\n",
        "''' Scaling Data '''\n",
        "# Scaling Data\n",
        "data = data.map(lambda x,y: (x/255, y))\n",
        "data.as_numpy_iterator().next()[0].max()\n",
        "\n",
        "\n",
        "''' Splitting Data '''\n",
        "train_size = int(len(data)*.7)\n",
        "val_size = int(len(data)*.1)\n",
        "test_size = int(len(data)*.2)+1\n",
        "\n",
        "train = data.take(train_size)\n",
        "val = data.take(val_size)\n",
        "test = data.take(test_size)\n",
        "\n",
        "print(train_size, \"+\", test_size, \"+\", val_size, \"=\", len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNjz3dlbZPEL"
      },
      "source": [
        "# **Deep Learning Models Creation, Training, Evaluating, Saving, Performance Graph etc.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAIUbksF3w3X",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Deep Models XceptionNet, InceptionResnetV2, MobileNetV2\n",
        "\n",
        "''' Deep Model '''\n",
        "# The Network\n",
        "import keras.backend as K\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, Dropout, AveragePooling2D, Concatenate, GlobalAveragePooling2D, BatchNormalization, ReLU, Add, SeparableConv2D\n",
        "from tensorflow.keras.applications import MobileNetV2, InceptionResNetV2, Xception\n",
        "\n",
        "\n",
        "def xception(img_shape, n_classes):\n",
        "    xceptionnet = Xception(input_shape=img_shape, include_top=False, weights='imagenet')\n",
        "    xceptionnet.trainable = False\n",
        "\n",
        "    input = Input(img_shape)\n",
        "    x = xceptionnet(input, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(rate = 0.2)(x)\n",
        "\n",
        "    output = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(input, output)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def inceptionresnetv2(img_shape, n_classes):\n",
        "    inceptionresnet = InceptionResNetV2(input_shape=img_shape, include_top=False, weights='imagenet')\n",
        "    inceptionresnet.trainable = False\n",
        "\n",
        "    input = Input(img_shape)\n",
        "    x = inceptionresnet(input, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(rate = 0.2)(x)\n",
        "\n",
        "    output = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(input, output)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mobilenetv2(img_shape, n_classes):\n",
        "    mobilenet = MobileNetV2(input_shape=img_shape, include_top=False, weights='imagenet')\n",
        "    mobilenet.trainable = False\n",
        "\n",
        "    input = Input(img_shape)\n",
        "    x = mobilenet(input, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(rate = 0.2)(x)\n",
        "\n",
        "    output = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(input, output)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_shape = (256, 256, 3)\n",
        "n_classes = 3\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "opt = SGD(learning_rate=0.1)\n",
        "\n",
        "model1 = xception(input_shape, n_classes)\n",
        "model1.compile('Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model1.summary()\n",
        "\n",
        "model2 = inceptionresnetv2(input_shape, n_classes)\n",
        "model2.compile('Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.summary()\n",
        "\n",
        "model3 = mobilenetv2(input_shape, n_classes)\n",
        "model3.compile('Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XDDPSLqdU5Eo"
      },
      "outputs": [],
      "source": [
        "#@title Training the Models\n",
        "\n",
        "# Train\n",
        "logdir='/content/drive/My Drive/Colab Notebooks/logs'\n",
        "tensorboard_callback1 = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "hist1 = model1.fit(train, epochs=60, validation_data=val, callbacks=[tensorboard_callback1])\n",
        "print(hist1.history)\n",
        "\n",
        "tensorboard_callback2 = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "hist2 = model2.fit(train, epochs=60, validation_data=val, callbacks=[tensorboard_callback2])\n",
        "print(hist2.history)\n",
        "\n",
        "tensorboard_callback3 = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "hist3 = model3.fit(train, epochs=60, validation_data=val, callbacks=[tensorboard_callback3])\n",
        "print(hist3.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OEzO9JMAVA9a"
      },
      "outputs": [],
      "source": [
        "#@title Evaluating the Models\n",
        "\n",
        "''' Evaluation '''\n",
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy, sparse_categorical_accuracy\n",
        "from sklearn.metrics import *\n",
        "\n",
        "loss1, results1 = model1.evaluate(test, batch_size=328, callbacks=[tensorboard_callback1])\n",
        "loss2, results2 = model2.evaluate(test, batch_size=328, callbacks=[tensorboard_callback2])\n",
        "loss3, results3 = model3.evaluate(test, batch_size=328, callbacks=[tensorboard_callback3])\n",
        "print(\"Result1 : \\n\", results1, \"\\nResult2 : \\n\", results2, \"\\nResult3 : \\n\", results3)\n",
        "print(\"Loss1: \\n\", loss1, \"\\nLoss2: \\n\", loss2, \"\\nLoss3: \\n\", loss3)\n",
        "\n",
        "pre1 = Precision()\n",
        "re1 = Recall()\n",
        "acc1 = BinaryAccuracy()\n",
        "for batch1 in test.as_numpy_iterator():\n",
        "    X1, y1 = batch1\n",
        "    yhat1 = model1.predict(X1)\n",
        "    max = a = 0\n",
        "    arr = np.ones(yhat1.shape[0])*-1\n",
        "    for i in yhat1:\n",
        "        if ((i[0] > i[1]) and (i[0] > i[2])):\n",
        "            max = 0\n",
        "        elif ((i[1] > i[0]) and (i[1] > i[2])):\n",
        "            max = 1\n",
        "        else:\n",
        "            max = 2\n",
        "        arr[a] = max\n",
        "        a+=1\n",
        "    pre1.update_state(y1, arr)\n",
        "    re1.update_state(y1, arr)\n",
        "    acc1.update_state(y1, arr)\n",
        "acc11 = sparse_categorical_accuracy(y1, yhat1)\n",
        "assert acc11.shape == (y1.shape[0],)\n",
        "print(f'Precision:{pre1.result().numpy()}, Recall:{re1.result().numpy()}, Accuracy (Binary):{acc1.result().numpy()}, Accuracy (sparse_categorical):{acc11.numpy()}')\n",
        "matrix = confusion_matrix(y1, arr)\n",
        "print(\"Confusion Matrix for Model 1: \\n\", matrix)\n",
        "display = ConfusionMatrixDisplay(confusion_matrix = matrix, display_labels = ['Benign', 'Malignant', 'Normal'])\n",
        "display.plot()\n",
        "plt.show()\n",
        "\n",
        "pre2 = Precision()\n",
        "re2 = Recall()\n",
        "acc2 = BinaryAccuracy()\n",
        "for batch2 in test.as_numpy_iterator():\n",
        "    X2, y2 = batch2\n",
        "    yhat2 = model2.predict(X2)\n",
        "    max = a = 0\n",
        "    arr = np.ones(yhat2.shape[0])*-1\n",
        "    for i in yhat1:\n",
        "        if ((i[0] > i[1]) and (i[0] > i[2])):\n",
        "            max = 0\n",
        "        elif ((i[1] > i[0]) and (i[1] > i[2])):\n",
        "            max = 1\n",
        "        else:\n",
        "            max = 2\n",
        "        arr[a] = max\n",
        "        a+=1\n",
        "    pre2.update_state(y2, arr)\n",
        "    re2.update_state(y2, arr)\n",
        "    acc2.update_state(y2, arr)\n",
        "acc21 = sparse_categorical_accuracy(y2, yhat2)\n",
        "assert acc21.shape == (y2.shape[0],)\n",
        "print(f'Precision:{pre2.result().numpy()}, Recall:{re2.result().numpy()}, Accuracy (Binary):{acc2.result().numpy()}, Accuracy (sparse_categorical):{acc21.numpy()}')\n",
        "matrix = confusion_matrix(y2, arr)\n",
        "print(\"Confusion Matrix for Model 2: \\n\", matrix)\n",
        "display = ConfusionMatrixDisplay(confusion_matrix = matrix, display_labels = ['Benign', 'Malignant', 'Normal'])\n",
        "display.plot()\n",
        "plt.show()\n",
        "\n",
        "pre3 = Precision()\n",
        "re3 = Recall()\n",
        "acc3 = BinaryAccuracy()\n",
        "for batch3 in test.as_numpy_iterator():\n",
        "    X3, y3 = batch3\n",
        "    yhat3 = model3.predict(X3)\n",
        "    max = a = 0\n",
        "    arr = np.ones(yhat3.shape[0])*-1\n",
        "    for i in yhat1:\n",
        "        if ((i[0] > i[1]) and (i[0] > i[2])):\n",
        "            max = 0\n",
        "        elif ((i[1] > i[0]) and (i[1] > i[2])):\n",
        "            max = 1\n",
        "        else:\n",
        "            max = 2\n",
        "        arr[a] = max\n",
        "        a+=1\n",
        "    pre3.update_state(y3, arr)\n",
        "    re3.update_state(y3, arr)\n",
        "    acc3.update_state(y3, arr)\n",
        "acc31 = sparse_categorical_accuracy(y3, yhat3)\n",
        "assert acc31.shape == (y3.shape[0],)\n",
        "print(f'Precision:{pre3.result().numpy()}, Recall:{re3.result().numpy()}, Accuracy (Binary):{acc3.result().numpy()}, Accuracy (sparse_categorical):{acc31.numpy()}')\n",
        "matrix = confusion_matrix(y3, arr)\n",
        "print(\"Confusion Matrix for Model 3: \\n\", matrix)\n",
        "display = ConfusionMatrixDisplay(confusion_matrix = matrix, display_labels = ['Benign', 'Malignant', 'Normal'])\n",
        "display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hBbI8OQlAPBK"
      },
      "outputs": [],
      "source": [
        "#@title Saving the Models and their Histories\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Saving the Models\n",
        "\n",
        "model1.save(os.path.join('/content/drive/My Drive/Colab Notebooks/models','imageclassifier1.h5'))\n",
        "model2.save(os.path.join('/content/drive/My Drive/Colab Notebooks/models','imageclassifier2.h5'))\n",
        "model3.save(os.path.join('/content/drive/My Drive/Colab Notebooks/models','imageclassifier3.h5'))\n",
        "\n",
        "\n",
        "# Saving the Model Histories\n",
        "\n",
        "with open(os.path.join(logdir+'/history1.pkl'), 'wb') as file:\n",
        "    pickle.dump(hist1, file)\n",
        "\n",
        "with open(os.path.join(logdir+'/history2.pkl'), 'wb') as file:\n",
        "    pickle.dump(hist2, file)\n",
        "\n",
        "with open(os.path.join(logdir+'/history3.pkl'), 'wb') as file:\n",
        "    pickle.dump(hist3, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_aEnAxJpjcsP"
      },
      "outputs": [],
      "source": [
        "#@title Re-Loading the Models and their Histories\n",
        "\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "logdir='/content/drive/My Drive/Colab Notebooks/logs'\n",
        "\n",
        "# Loading the Models\n",
        "model1 = load_model('/content/drive/My Drive/Colab Notebooks/models/imageclassifier1.h5')\n",
        "model2 = load_model('/content/drive/My Drive/Colab Notebooks/models/imageclassifier2.h5')\n",
        "model3 = load_model('/content/drive/My Drive/Colab Notebooks/models/imageclassifier3.h5')\n",
        "\n",
        "\n",
        "# Loading the Model Histories\n",
        "\n",
        "with open(os.path.join(logdir+'/history1.pkl'), 'rb') as file:\n",
        "    hist1 = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(logdir+'/history2.pkl'), 'rb') as file:\n",
        "    hist2 = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(logdir+'/history3.pkl'), 'rb') as file:\n",
        "    hist3 = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7enTu7l3W2Ui"
      },
      "outputs": [],
      "source": [
        "#@title Performance Graphs\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "''' Model 1 '''\n",
        "# Loss\n",
        "fig = plt.figure()\n",
        "plt.title(\"Model 1\\n\", loc='center', fontsize=26)\n",
        "plt.plot(hist1.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist1.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "# Accuracy\n",
        "fig = plt.figure()\n",
        "plt.plot(hist1.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist1.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "''' Model 2 '''\n",
        "# Loss\n",
        "fig = plt.figure()\n",
        "plt.title(\"Model 2\\n\", loc='center', fontsize=26)\n",
        "plt.plot(hist2.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist2.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "# Accuracy\n",
        "fig = plt.figure()\n",
        "plt.plot(hist2.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist2.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "''' Model 3 '''\n",
        "# Loss\n",
        "fig = plt.figure()\n",
        "plt.title(\"Model 3\\n\", loc='center', fontsize=26)\n",
        "plt.plot(hist3.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist3.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "# Accuracy\n",
        "fig = plt.figure()\n",
        "plt.plot(hist3.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist3.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Precision, Recall and Accuracy of the Models with respect to all images in dataset\n",
        "\n",
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy, sparse_categorical_accuracy\n",
        "from sklearn.metrics import *\n",
        "\n",
        "labels = []; p1 = []; p2 = []; p3 = []\n",
        "pre1 = Precision()\n",
        "re1 = Recall()\n",
        "acc1 = BinaryAccuracy()\n",
        "for j in data_dir:\n",
        "    for c, image_class in enumerate(os.listdir(j)):\n",
        "        for image in os.listdir(os.path.join(j, image_class)):\n",
        "            image_path = os.path.join(j, image_class, image)\n",
        "            img = cv2.imread(image_path)\n",
        "            resize = tf.image.resize(img, (256, 256))\n",
        "\n",
        "            yhat1 = model1.predict(np.expand_dims(resize/255, 0), verbose=0)\n",
        "            yhat2 = model2.predict(np.expand_dims(resize/255, 0), verbose=0)\n",
        "            yhat3 = model3.predict(np.expand_dims(resize/255, 0), verbose=0)\n",
        "            max = 0\n",
        "            for i in yhat1:\n",
        "                if ((i[0] > i[1]) and (i[0] > i[2])):\n",
        "                    max = 0\n",
        "                elif ((i[1] > i[0]) and (i[1] > i[2])):\n",
        "                    max = 1\n",
        "                else:\n",
        "                    max = 2\n",
        "                p1.append(max)\n",
        "\n",
        "            max = 0\n",
        "            for i in yhat2:\n",
        "                if ((i[0] > i[1]) and (i[0] > i[2])):\n",
        "                    max = 0\n",
        "                elif ((i[1] > i[0]) and (i[1] > i[2])):\n",
        "                    max = 1\n",
        "                else:\n",
        "                    max = 2\n",
        "                p2.append(max)\n",
        "\n",
        "            max = 0\n",
        "            for i in yhat3:\n",
        "                if ((i[0] > i[1]) and (i[0] > i[2])):\n",
        "                    max = 0\n",
        "                elif ((i[1] > i[0]) and (i[1] > i[2])):\n",
        "                    max = 1\n",
        "                else:\n",
        "                    max = 2\n",
        "                p3.append(max)\n",
        "\n",
        "            labels.append(c)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "p1 = np.asarray(p1)\n",
        "p2 = np.asarray(p2)\n",
        "p3 = np.asarray(p3)\n",
        "\n",
        "print(\"Xception : \", end=\"\")\n",
        "for i in p1:\n",
        "    print(i, end=\" \")\n",
        "print(\"\\nInceptionResNetV2 : \", end=\"\")\n",
        "for i in p2:\n",
        "    print(i, end = \" \")\n",
        "print(\"\\nMobileNetV2 : \", end=\"\")\n",
        "for i in p3:\n",
        "    print(i, end=\" \")\n",
        "print()\n",
        "\n",
        "pre1.update_state(labels, p1)\n",
        "re1.update_state(labels, p1)\n",
        "acc1.update_state(labels, p1)\n",
        "print(f'Precision:{pre1.result().numpy()}, Recall:{re1.result().numpy()}, Accuracy (Binary):{acc1.result().numpy()}')\n",
        "matrix = confusion_matrix(labels, p1)\n",
        "print(\"Confusion Matrix for Model 1: \\n\", matrix)\n",
        "display = ConfusionMatrixDisplay(confusion_matrix = matrix, display_labels = ['Benign', 'Malignant', 'Normal'])\n",
        "display.plot()\n",
        "plt.show()\n",
        "\n",
        "pre1 = Precision()\n",
        "re1 = Recall()\n",
        "acc1 = BinaryAccuracy()\n",
        "pre1.update_state(labels, p2)\n",
        "re1.update_state(labels, p2)\n",
        "acc1.update_state(labels, p2)\n",
        "print(f'Precision:{pre1.result().numpy()}, Recall:{re1.result().numpy()}, Accuracy (Binary):{acc1.result().numpy()}')\n",
        "matrix = confusion_matrix(labels, p2)\n",
        "print(\"Confusion Matrix for Model 2: \\n\", matrix)\n",
        "display = ConfusionMatrixDisplay(confusion_matrix = matrix, display_labels = ['Benign', 'Malignant', 'Normal'])\n",
        "display.plot()\n",
        "plt.show()\n",
        "\n",
        "pre1 = Precision()\n",
        "re1 = Recall()\n",
        "acc1 = BinaryAccuracy()\n",
        "pre1.update_state(labels, p3)\n",
        "re1.update_state(labels, p3)\n",
        "acc1.update_state(labels, p3)\n",
        "print(f'Precision:{pre1.result().numpy()}, Recall:{re1.result().numpy()}, Accuracy (Binary):{acc1.result().numpy()}')\n",
        "matrix = confusion_matrix(labels, p3)\n",
        "print(\"Confusion Matrix for Model 3: \\n\", matrix)\n",
        "display = ConfusionMatrixDisplay(confusion_matrix = matrix, display_labels = ['Benign', 'Malignant', 'Normal'])\n",
        "display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YQHMHMPSf7lA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgRByXkyZ3Ku"
      },
      "source": [
        "# **Predictions by each model and Probability Extraction for Fuzzy Ensemble of Deep Neural Networks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CkxFb0uuNHZ6"
      },
      "outputs": [],
      "source": [
        "#@title Predictions of each Model and Probability Extraction from Models\n",
        "\n",
        "# Getting Probability Distribution\n",
        "\n",
        "print(\"\\nGetting the Probability Distribution\")\n",
        "loss1, results1 = model1.evaluate(test, batch_size=328, callbacks=[tensorboard_callback1])\n",
        "loss2, results2 = model2.evaluate(test, batch_size=328, callbacks=[tensorboard_callback2])\n",
        "loss3, results3 = model3.evaluate(test, batch_size=328, callbacks=[tensorboard_callback3])\n",
        "print(\"Result1 : \\n\", results1, \"\\nResult2 : \\n\", results2, \"\\nResult3 : \\n\", results3)\n",
        "print(\"Loss1: \\n\", loss1, \"\\nLoss2: \\n\", loss2, \"\\nLoss3: \\n\", loss3)\n",
        "\n",
        "predictions11 = model1.predict(test, batch_size=328, callbacks=[tensorboard_callback1])\n",
        "predictions21 = model2.predict(test, batch_size=328, callbacks=[tensorboard_callback2])\n",
        "predictions31 = model3.predict(test, batch_size=328, callbacks=[tensorboard_callback3])\n",
        "\n",
        "predictions1 = model1.predict(train)\n",
        "prediction_classes = [1 if ((prob[1] > prob[0]) and (prob[1] > prob[2])) else 2 if ((prob[2] > prob[0]) and (prob[2] > prob[1])) else 0 for prob in predictions1]\n",
        "print(np.ravel(predictions1))\n",
        "print(\"Model 1 : \\n\", prediction_classes)\n",
        "\n",
        "predictions2 = model2.predict(train)\n",
        "prediction_classes = [1 if ((prob[1] > prob[0]) and (prob[1] > prob[2])) else 2 if ((prob[2] > prob[0]) and (prob[2] > prob[1])) else 0 for prob in predictions2]\n",
        "print(\"Model 2 : \\n\", prediction_classes)\n",
        "\n",
        "predictions3 = model3.predict(train)\n",
        "prediction_classes = [1 if ((prob[1] > prob[0]) and (prob[1] > prob[2])) else 2 if ((prob[2] > prob[0]) and (prob[2] > prob[1])) else 0 for prob in predictions3]\n",
        "print(\"Model 3 : \\n\", prediction_classes)\n",
        "\n",
        "\n",
        "p1 = []\n",
        "p2 = []\n",
        "p3 = []\n",
        "\n",
        "for i in data_dir:\n",
        "    for image_class in os.listdir(i):\n",
        "        for image in os.listdir(os.path.join(i, image_class)):\n",
        "            image_path = os.path.join(i, image_class, image)\n",
        "            img = cv2.imread(image_path)\n",
        "            resize = tf.image.resize(img, (256, 256))\n",
        "\n",
        "            yhat1 = model1.predict(np.expand_dims(resize/255, 0))\n",
        "            yhat2 = model2.predict(np.expand_dims(resize/255, 0))\n",
        "            yhat3 = model3.predict(np.expand_dims(resize/255, 0))\n",
        "\n",
        "            p1.append(yhat1[0])\n",
        "            p2.append(yhat2[0])\n",
        "            p3.append(yhat3[0])\n",
        "\n",
        "p1 = np.array(p1)\n",
        "p2 = np.array(p2)\n",
        "p3 = np.array(p3)\n",
        "\n",
        "import csv\n",
        "fp = open(\"/content/drive/My Drive/Colab Notebooks/csv/xceptionnet.csv\",'w+',newline = '')\n",
        "writer = csv.writer(fp)\n",
        "for i in p1:\n",
        "    writer.writerow([i[0], i[1], i[2]])\n",
        "fp.close()\n",
        "\n",
        "fp = open(\"/content/drive/My Drive/Colab Notebooks/csv/inceptionresnet.csv\",'w+',newline = '')\n",
        "writer = csv.writer(fp)\n",
        "for i in p2:\n",
        "    writer.writerow([i[0], i[1], i[2]])\n",
        "fp.close()\n",
        "\n",
        "fp = open(\"/content/drive/My Drive/Colab Notebooks/csv/mobilenetv2.csv\",'w+',newline = '')\n",
        "writer = csv.writer(fp)\n",
        "for i in p3:\n",
        "    writer.writerow([i[0], i[1], i[2]])\n",
        "fp.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eFXAngThuGbU"
      },
      "outputs": [],
      "source": [
        "#@title ROC-AUC Curves\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import *\n",
        "import math, os\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "#ROC-AUC\n",
        "from sklearn.metrics import roc_curve,auc\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_roc(val_label,decision_val, caption='ROC Curve'):\n",
        "    num_classes=np.unique(val_label).shape[0]\n",
        "    classes = []\n",
        "    for i in range(num_classes):\n",
        "        classes.append(i)\n",
        "    plt.figure()\n",
        "    decision_val = label_binarize(decision_val, classes=classes)\n",
        "\n",
        "    if num_classes!=2:\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        for i in range(num_classes):\n",
        "            y_val = label_binarize(val_label, classes=classes)\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_val[:, i], decision_val[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        for i in range(num_classes):\n",
        "            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                                           ''.format(i+1, roc_auc[i]))\n",
        "    else:\n",
        "        fpr,tpr,_ = roc_curve(val_label,decision_val, pos_label=1)\n",
        "        roc_auc = auc(fpr,tpr)*100\n",
        "        plt.plot(fpr,tpr,label='ROC curve (AUC=%0.2f)'%roc_auc)\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(caption)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(str(len(classes))+'.png',dpi=300)\n",
        "\n",
        "def predicting(ensemble_prob):\n",
        "    prediction = np.zeros((ensemble_prob.shape[0],))\n",
        "    for i in range(ensemble_prob.shape[0]):\n",
        "        temp = ensemble_prob[i]\n",
        "        t = np.where(temp == np.max(temp))[0][0]\n",
        "        prediction[i] = t\n",
        "    return prediction\n",
        "\n",
        "def metrics(labels, predictions,classes):\n",
        "    print(\"Classification Report:\")\n",
        "    print(\"Labels : \",labels.shape, '\\nPredictions : ', predictions.shape)\n",
        "    print(classification_report(labels, predictions, target_names = classes, digits = 4))\n",
        "    matrix = confusion_matrix(labels, predictions)\n",
        "    print(\"Confusion matrix:\")\n",
        "    print(matrix)\n",
        "    display = ConfusionMatrixDisplay(confusion_matrix = matrix, display_labels = ['Benign', 'Malignant', 'Normal'])\n",
        "    display.plot()\n",
        "    plt.show()\n",
        "    print(\"\\nClasswise Accuracy :{}\".format(matrix.diagonal()/matrix.sum(axis = 1)))\n",
        "    print(\"\\nBalanced Accuracy Score: \",balanced_accuracy_score(labels,predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Fuzzy Ensemble using Mitcherlich Function***"
      ],
      "metadata": {
        "id": "elLENXLqrgrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predictions with Mitcherlich Function\n",
        "\n",
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def fuzzy_rank(CF, top):\n",
        "    R_L = np.zeros(CF.shape)\n",
        "    for i in range(CF.shape[0]):\n",
        "        for j in range(CF.shape[1]):\n",
        "            for k in range(CF.shape[2]):\n",
        "                R_L[i][j][k] = (2 - 1 * 2 ** CF[i][j][k])\n",
        "\n",
        "    K_L = 1*np.ones(shape = R_L.shape)\n",
        "    for i in range(R_L.shape[0]):\n",
        "        for sample in range(R_L.shape[1]):\n",
        "            for k in range(top-1):\n",
        "                a = R_L[i][sample]\n",
        "                idx = np.where(a==np.partition(a, k)[k])\n",
        "                K_L[i][sample][idx] = R_L[i][sample][idx]\n",
        "\n",
        "    return K_L\n",
        "\n",
        "def CFS_func(CF, K_L):\n",
        "    H = CF.shape[0]\n",
        "    for f in range(CF.shape[0]):\n",
        "        for i in range(CF.shape[1]):\n",
        "            idx = np.where(K_L[f][i] == 1)\n",
        "            CF[f][i][idx] = 0\n",
        "    CFS = 1 - np.sum(CF,axis=0)/H\n",
        "    return CFS\n",
        "\n",
        "def Mitcherlich(top = 2, *argv):\n",
        "    L = 0\n",
        "    for arg in argv:\n",
        "        L += 1\n",
        "\n",
        "    num_classes = arg.shape[1]\n",
        "    CF = np.zeros(shape = (L,arg.shape[0], arg.shape[1]))\n",
        "\n",
        "    for i, arg in enumerate(argv):\n",
        "        CF[:][:][i] = arg\n",
        "\n",
        "    R_L = fuzzy_rank(CF, top)\n",
        "\n",
        "    RS = np.sum(R_L, axis=0)\n",
        "    CFS = CFS_func(CF, R_L)\n",
        "    FS = RS*CFS\n",
        "\n",
        "\n",
        "    predictions = np.argmin(FS,axis=1)\n",
        "    return predictions\n",
        "\n",
        "def getfile(filename):\n",
        "    root='/content/drive/My Drive/Colab Notebooks/csv/'\n",
        "    file = root+filename\n",
        "    if '.csv' not in filename:\n",
        "        file = file+'.csv'\n",
        "    df = pd.read_csv(file,header=None)\n",
        "    df = np.asarray(df)\n",
        "\n",
        "    labels=[]\n",
        "    for k in data_dir:\n",
        "        for i, c in enumerate(os.listdir(k)):\n",
        "            for j in range(len(os.listdir(k+\"/\"+c))):\n",
        "                labels.append(i)\n",
        "    labels = np.asarray(labels)\n",
        "    return df,labels\n",
        "\n",
        "p1,labels = getfile(\"xceptionnet\")\n",
        "p2,_ = getfile(\"inceptionresnet\")\n",
        "p3,_ = getfile(\"mobilenetv2\")\n",
        "\n",
        "predictions = Mitcherlich(3, p1, p2, p3)\n",
        "for i in predictions:\n",
        "    print(i, end=\" \")\n",
        "print()\n",
        "\n",
        "correct = np.where(predictions == labels)[0].shape[0]\n",
        "total = labels.shape[0]\n",
        "\n",
        "classes = []\n",
        "for i in range(p1.shape[1]):\n",
        "    classes.append(str(i+1))\n",
        "print(classes)\n",
        "\n",
        "metrics(labels, predictions, classes)\n",
        "\n",
        "plot_roc(labels,predictions)\n",
        "\n",
        "\n",
        "avg_acc_list = []\n",
        "avg_precision_list = []\n",
        "avg_recall_list = []\n",
        "avg_f1_list = []\n",
        "\n",
        "acc_fold = accuracy_score(labels, predictions)\n",
        "avg_acc_list.append(acc_fold)\n",
        "precision_fold = precision_score(labels, predictions, average='macro')\n",
        "avg_precision_list.append(precision_fold)\n",
        "recall_fold = recall_score(labels, predictions, average='macro')\n",
        "avg_recall_list.append(recall_fold)\n",
        "f1_fold  = f1_score(labels, predictions, average='macro')\n",
        "avg_f1_list.append(f1_fold)\n",
        "\n",
        "print('Accuracy[{:.4f}] Precision[{:.4f}] Recall[{:.4f}] F1[{:.4f}] ]'.format(acc_fold, precision_fold, recall_fold, f1_fold ))\n",
        "print('________________________________________________________________')\n",
        "\n",
        "avg_acc = np.asarray(avg_acc_list)\n",
        "avg_precision = np.asarray(avg_precision_list)\n",
        "avg_recall = np.asarray(avg_recall_list)\n",
        "avg_f1 = np.asarray(avg_f1_list)\n",
        "print(\"\\n\")\n",
        "print('Overall Accuracy[{:.4f}] Overall Precision[{:.4f}] Overall Recall[{:.4f}] Overall F1[{:.4f}]'.format(np.mean(avg_acc), np.mean(avg_precision), np.mean(avg_recall), np.mean(avg_f1)))"
      ],
      "metadata": {
        "id": "1CDEvzHTwAds",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KffHnnQycKEt",
        "IXKsyAjnY7sK",
        "jNjz3dlbZPEL",
        "tgRByXkyZ3Ku",
        "elLENXLqrgrb"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}